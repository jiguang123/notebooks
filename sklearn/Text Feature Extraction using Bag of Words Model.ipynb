{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Feature Extraction using Bag of Words Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the Zen of Python as our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zen = \"\"\"Beautiful is better than ugly.\n",
    "Explicit is better than implicit.\n",
    "Simple is better than complex.\n",
    "Complex is better than complicated.\n",
    "Flat is better than nested.\n",
    "Sparse is better than dense.\n",
    "Readability counts.\n",
    "Special cases aren't special enough to break the rules.\n",
    "Although practicality beats purity.\n",
    "Errors should never pass silently.\n",
    "Unless explicitly silenced.\n",
    "In the face of ambiguity, refuse the temptation to guess.\n",
    "There should be one-- and preferably only one --obvious way to do it.\n",
    "Although that way may not be obvious at first unless you're Dutch.\n",
    "Now is better than never.\n",
    "Although never is often better than *right* now.\n",
    "If the implementation is hard to explain, it's a bad idea.\n",
    "If the implementation is easy to explain, it may be a good idea.\n",
    "Namespaces are one honking great idea -- let's do more of those!\"\"\"\n",
    "\n",
    "lines = [l.lower() for l in zen.splitlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beautiful is better than ugly.',\n",
       " 'explicit is better than implicit.',\n",
       " 'simple is better than complex.',\n",
       " 'complex is better than complicated.',\n",
       " 'flat is better than nested.',\n",
       " 'sparse is better than dense.',\n",
       " 'readability counts.',\n",
       " \"special cases aren't special enough to break the rules.\",\n",
       " 'although practicality beats purity.',\n",
       " 'errors should never pass silently.',\n",
       " 'unless explicitly silenced.',\n",
       " 'in the face of ambiguity, refuse the temptation to guess.',\n",
       " 'there should be one-- and preferably only one --obvious way to do it.',\n",
       " \"although that way may not be obvious at first unless you're dutch.\",\n",
       " 'now is better than never.',\n",
       " 'although never is often better than *right* now.',\n",
       " \"if the implementation is hard to explain, it's a bad idea.\",\n",
       " 'if the implementation is easy to explain, it may be a good idea.',\n",
       " \"namespaces are one honking great idea -- let's do more of those!\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'although': 0,\n",
       " 'ambiguity': 1,\n",
       " 'and': 2,\n",
       " 'are': 3,\n",
       " 'aren': 4,\n",
       " 'at': 5,\n",
       " 'bad': 6,\n",
       " 'be': 7,\n",
       " 'beats': 8,\n",
       " 'beautiful': 9,\n",
       " 'better': 10,\n",
       " 'break': 11,\n",
       " 'cases': 12,\n",
       " 'complex': 13,\n",
       " 'complicated': 14,\n",
       " 'counts': 15,\n",
       " 'dense': 16,\n",
       " 'do': 17,\n",
       " 'dutch': 18,\n",
       " 'easy': 19,\n",
       " 'enough': 20,\n",
       " 'errors': 21,\n",
       " 'explain': 22,\n",
       " 'explicit': 23,\n",
       " 'explicitly': 24,\n",
       " 'face': 25,\n",
       " 'first': 26,\n",
       " 'flat': 27,\n",
       " 'good': 28,\n",
       " 'great': 29,\n",
       " 'guess': 30,\n",
       " 'hard': 31,\n",
       " 'honking': 32,\n",
       " 'idea': 33,\n",
       " 'if': 34,\n",
       " 'implementation': 35,\n",
       " 'implicit': 36,\n",
       " 'in': 37,\n",
       " 'is': 38,\n",
       " 'it': 39,\n",
       " 'let': 40,\n",
       " 'may': 41,\n",
       " 'more': 42,\n",
       " 'namespaces': 43,\n",
       " 'nested': 44,\n",
       " 'never': 45,\n",
       " 'not': 46,\n",
       " 'now': 47,\n",
       " 'obvious': 48,\n",
       " 'of': 49,\n",
       " 'often': 50,\n",
       " 'one': 51,\n",
       " 'only': 52,\n",
       " 'pass': 53,\n",
       " 'practicality': 54,\n",
       " 'preferably': 55,\n",
       " 'purity': 56,\n",
       " 're': 57,\n",
       " 'readability': 58,\n",
       " 'refuse': 59,\n",
       " 'right': 60,\n",
       " 'rules': 61,\n",
       " 'should': 62,\n",
       " 'silenced': 63,\n",
       " 'silently': 64,\n",
       " 'simple': 65,\n",
       " 'sparse': 66,\n",
       " 'special': 67,\n",
       " 'temptation': 68,\n",
       " 'than': 69,\n",
       " 'that': 70,\n",
       " 'the': 71,\n",
       " 'there': 72,\n",
       " 'those': 73,\n",
       " 'to': 74,\n",
       " 'ugly': 75,\n",
       " 'unless': 76,\n",
       " 'way': 77,\n",
       " 'you': 78}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cvec = CountVectorizer().fit(lines)\n",
    "cvec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 79)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow = cvec.transform(lines)\n",
    "bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['although',\n",
       " 'ambiguity',\n",
       " 'and',\n",
       " 'are',\n",
       " 'aren',\n",
       " 'at',\n",
       " 'bad',\n",
       " 'be',\n",
       " 'beats',\n",
       " 'beautiful',\n",
       " 'better',\n",
       " 'break',\n",
       " 'cases',\n",
       " 'complex',\n",
       " 'complicated',\n",
       " 'counts',\n",
       " 'dense',\n",
       " 'do',\n",
       " 'dutch',\n",
       " 'easy',\n",
       " 'enough',\n",
       " 'errors',\n",
       " 'explain',\n",
       " 'explicit',\n",
       " 'explicitly',\n",
       " 'face',\n",
       " 'first',\n",
       " 'flat',\n",
       " 'good',\n",
       " 'great',\n",
       " 'guess',\n",
       " 'hard',\n",
       " 'honking',\n",
       " 'idea',\n",
       " 'if',\n",
       " 'implementation',\n",
       " 'implicit',\n",
       " 'in',\n",
       " 'is',\n",
       " 'it',\n",
       " 'let',\n",
       " 'may',\n",
       " 'more',\n",
       " 'namespaces',\n",
       " 'nested',\n",
       " 'never',\n",
       " 'not',\n",
       " 'now',\n",
       " 'obvious',\n",
       " 'of',\n",
       " 'often',\n",
       " 'one',\n",
       " 'only',\n",
       " 'pass',\n",
       " 'practicality',\n",
       " 'preferably',\n",
       " 'purity',\n",
       " 're',\n",
       " 'readability',\n",
       " 'refuse',\n",
       " 'right',\n",
       " 'rules',\n",
       " 'should',\n",
       " 'silenced',\n",
       " 'silently',\n",
       " 'simple',\n",
       " 'sparse',\n",
       " 'special',\n",
       " 'temptation',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'there',\n",
       " 'those',\n",
       " 'to',\n",
       " 'ugly',\n",
       " 'unless',\n",
       " 'way',\n",
       " 'you']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Tfidf (Term-Frequency Inverse-Document Frequency) Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tfidf encoding rescales words that are common to have lesser weight (less important)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tvec = TfidfVectorizer().fit(lines)\n",
    "tvec.transform(lines).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tf-idfs are a way to represent documents as feature vectors. Tf-idfs can be understood as a modification of the raw term frequencies (tf); the tf is the count of how often a particular word occurs in a given document. The concept behind the tf-idf is to downweight terms proportionally to the number of documents in which they occur. Here, the idea is that terms that occur in many different documents are likely unimportant or don't contain any useful information for Natural Language Processing tasks such as document classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Order using n-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've used unigram tokenization: Each token represents a single element with regard to the splittting criterion. \n",
    "\n",
    "In some cases, word ordering may be of importance. In such cases, we use n-grams to consider **n** words as a token.\n",
    "\n",
    "For example consider: \"this is how you get ants\"\n",
    "- 1-gram: \"this\", \"is\", \"how\", \"you\", \"get\", \"ants\"\n",
    "- 2-gram: \"this is\", \"is how\", \"how you\", \"you get\", \"get ants\"\n",
    "- 3-gram: \"this is how\", \"is how you\", \"how you get\", \"you get ants\"\n",
    "\n",
    "Now, let's try using a bigram model with `CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['although never',\n",
       " 'although practicality',\n",
       " 'although that',\n",
       " 'ambiguity refuse',\n",
       " 'and preferably',\n",
       " 'are one',\n",
       " 'aren special',\n",
       " 'at first',\n",
       " 'bad idea',\n",
       " 'be good',\n",
       " 'be obvious',\n",
       " 'be one',\n",
       " 'beats purity',\n",
       " 'beautiful is',\n",
       " 'better than',\n",
       " 'break the',\n",
       " 'cases aren',\n",
       " 'complex is',\n",
       " 'do it',\n",
       " 'do more',\n",
       " 'easy to',\n",
       " 'enough to',\n",
       " 'errors should',\n",
       " 'explain it',\n",
       " 'explicit is',\n",
       " 'explicitly silenced',\n",
       " 'face of',\n",
       " 'first unless',\n",
       " 'flat is',\n",
       " 'good idea',\n",
       " 'great idea',\n",
       " 'hard to',\n",
       " 'honking great',\n",
       " 'idea let',\n",
       " 'if the',\n",
       " 'implementation is',\n",
       " 'in the',\n",
       " 'is better',\n",
       " 'is easy',\n",
       " 'is hard',\n",
       " 'is often',\n",
       " 'it bad',\n",
       " 'it may',\n",
       " 'let do',\n",
       " 'may be',\n",
       " 'may not',\n",
       " 'more of',\n",
       " 'namespaces are',\n",
       " 'never is',\n",
       " 'never pass',\n",
       " 'not be',\n",
       " 'now is',\n",
       " 'obvious at',\n",
       " 'obvious way',\n",
       " 'of ambiguity',\n",
       " 'of those',\n",
       " 'often better',\n",
       " 'one and',\n",
       " 'one honking',\n",
       " 'one obvious',\n",
       " 'only one',\n",
       " 'pass silently',\n",
       " 'practicality beats',\n",
       " 'preferably only',\n",
       " 're dutch',\n",
       " 'readability counts',\n",
       " 'refuse the',\n",
       " 'right now',\n",
       " 'should be',\n",
       " 'should never',\n",
       " 'simple is',\n",
       " 'sparse is',\n",
       " 'special cases',\n",
       " 'special enough',\n",
       " 'temptation to',\n",
       " 'than complex',\n",
       " 'than complicated',\n",
       " 'than dense',\n",
       " 'than implicit',\n",
       " 'than nested',\n",
       " 'than never',\n",
       " 'than right',\n",
       " 'than ugly',\n",
       " 'that way',\n",
       " 'the face',\n",
       " 'the implementation',\n",
       " 'the rules',\n",
       " 'the temptation',\n",
       " 'there should',\n",
       " 'to break',\n",
       " 'to do',\n",
       " 'to explain',\n",
       " 'to guess',\n",
       " 'unless explicitly',\n",
       " 'unless you',\n",
       " 'way may',\n",
       " 'way to',\n",
       " 'you re']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bivec = CountVectorizer(ngram_range=(2,2)).fit(lines)\n",
    "bivec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bivec.transform(lines).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What value of n should you consider?\n",
    "\n",
    "*It depends on the algorithm, dataset and goal. Consider n as a tuning paramater and adjust it accordingly.*\n",
    "\n",
    "For example, consider the below snippet to find the most common uni-, bi- and tri-gram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common 1-gram: is\n",
      "Most common 2-gram: better than\n",
      "Most common 3-gram: is better than\n"
     ]
    }
   ],
   "source": [
    "for n in range(1, 4):\n",
    "    bivec = CountVectorizer(ngram_range=(n,n)).fit(lines)\n",
    "    data = bivec.transform(lines)\n",
    "    most_common = np.argmax(data.sum(axis=0))\n",
    "    \n",
    "    feature = bivec.get_feature_names()[most_common]\n",
    "    print(\"Most common {}-gram: {}\".format(n, feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it all depends on the context of what you are trying to achieve."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
